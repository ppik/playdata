{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expedia Hotel Recommendations Kaggle competition\n",
    "\n",
    "Peeter Piksarv (piksarv .at. gmail.com)\n",
    "\n",
    "The latest version of this Jupyter notebook is available at https://github.com/ppik/playdata/tree/master/Kaggle-Expedia\n",
    "\n",
    "This is my take on that particular Kaggle competition started off using [Dataquest tutorial](https://www.dataquest.io/blog/kaggle-tutorial/) by Vik Paruchuri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ml_metrics as metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.ensemble\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "Actually don't need to unpack gzipped cvs files, pandas' `read_csv` can handle those, although it can be slower (Reading 1000000 rows from `train.csv.gz` seems to be about 9% slower than from `train.csv` on my laptop).\n",
    "\n",
    "Additionally, it's a good idea to specify the data types for each column tho ease the memory requirements. By default pandas detects the following data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 24 columns):\n",
      "date_time                    10 non-null object\n",
      "site_name                    10 non-null int64\n",
      "posa_continent               10 non-null int64\n",
      "user_location_country        10 non-null int64\n",
      "user_location_region         10 non-null int64\n",
      "user_location_city           10 non-null int64\n",
      "orig_destination_distance    6 non-null float64\n",
      "user_id                      10 non-null int64\n",
      "is_mobile                    10 non-null int64\n",
      "is_package                   10 non-null int64\n",
      "channel                      10 non-null int64\n",
      "srch_ci                      10 non-null object\n",
      "srch_co                      10 non-null object\n",
      "srch_adults_cnt              10 non-null int64\n",
      "srch_children_cnt            10 non-null int64\n",
      "srch_rm_cnt                  10 non-null int64\n",
      "srch_destination_id          10 non-null int64\n",
      "srch_destination_type_id     10 non-null int64\n",
      "is_booking                   10 non-null int64\n",
      "cnt                          10 non-null int64\n",
      "hotel_continent              10 non-null int64\n",
      "hotel_country                10 non-null int64\n",
      "hotel_market                 10 non-null int64\n",
      "hotel_cluster                10 non-null int64\n",
      "dtypes: float64(1), int64(20), object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv.gz', nrows=10)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to the specification the data fields are following:\n",
    "\n",
    "`train.csv`\n",
    "\n",
    "| Column name               | Description                                   | Data type | Equiv. type | Notes |\n",
    "|---------------------------|-----------------------------------------------|-----------|-------------|-------|\n",
    "| date_time                 | Timestamp                                     | string    |             | [1]   |\n",
    "| site_name                 | ID of the Expedia point of sale               | int       | np.int32    |       |\n",
    "| posa_continent            | ID of continent associated with site_name     | int       | np.int32    |       |\n",
    "| user_location_country     | The ID of the country the customer is located | int       | np.int32    |       |\n",
    "| user_location_region      | The ID of the region the customer is located  | int       | np.int32    |       |\n",
    "| user_location_city        | The ID of the city the customer is located    | int       | np.int32    |       |\n",
    "| orig_destination_distance | Physical distance between a hotel and a customer at the time of search. A null means the distance could not be calculated | double | np.float64 | |\n",
    "| user_id                   | ID of user                                    | int       | np.int32    |       |\n",
    "| is_mobile                 | 1 when a user connected from a mobile device, 0 otherwise | tinyint | np.uint8 | [2] |\n",
    "| is_package                | 1 if the click/booking was generated as a part of a package (i.e. combined with a flight), 0 otherwise | int | np.uint8 | [2] |\n",
    "| channel                   | ID of a marketing channel                     | int       | np.int32    |       |\n",
    "| srch_ci                   | Checkin date                                  | string    |             | [1]   |\n",
    "| srch_co                   | Checkout date                                 | string    |             | [1]   |\n",
    "| srch_adults_cnt           | The number of adults specified in the hotel room | int    | np.int32    |       |\n",
    "| srch_children_cnt         | The number of (extra occupancy) children specified in the hotel room | int | np.int32 | [4] |\n",
    "| srch_rm_cnt               | The number of hotel rooms specified in the search | int   | np.int32    | [4]   |\n",
    "| srch_destination_id       | ID of the destination where the hotel search was performed | int | np.int32 |   |\n",
    "| srch_destination_type_id  | Type of destination                           | int       | np.int32    |       |\n",
    "| hotel_continent           | Hotel continent                               | int       | np.int32    |       |\n",
    "| hotel_country             | Hotel country                                 | int       | np.int32    |       |\n",
    "| hotel_market              | Hotel market                                  | int       | np.int32    |       |\n",
    "| is_booking                | 1 if a booking, 0 if a click                  | tinyint   | np.uint8    | [2]   |\n",
    "| cnt                       | Numer of similar events in the context of the same user session | bigint | np.int64 | |\n",
    "| hotel_cluster             | ID of a hotel cluster                         | int       | np.int32    |       |\n",
    "\n",
    "`destinations.csv`\n",
    "\n",
    "| Column name         | Description                                                | Data type | Equiv. type | Notes |\n",
    "|---------------------|------------------------------------------------------------|-----------|-------------|-------|\n",
    "| srch_destination_id | ID of the destination where the hotel search was performed | int       | np.int32    |       |\n",
    "| d1-d149             | latent description of search regions                       | double    | np.float64  | [3,5] |\n",
    "\n",
    "### Notes\n",
    "1. Probably it would be good idea to parse dates while loading data. From date information useful features may include duration of the stay, season/month, how much in advance is the booking made, etc.\n",
    "2. May use np.bool instead.\n",
    "3. Single or even half-precision might be enough when starting to take account descriptions of search regions.\n",
    "4. If taking into account if the column srch_children_cnt or srch_room_cnt it may be worthwhile to simply this first to a boolean values if any number of children and/or rooms was specifien in the hotel room.\n",
    "5. Maybe the required clustering can be done solely on the base of latent descriptions of search regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traincols = ['date_time', 'site_name', 'posa_continent', 'user_location_country',\n",
    "             'user_location_region', 'user_location_city', 'orig_destination_distance',\n",
    "             'user_id', 'is_mobile', 'is_package', 'channel', 'srch_ci', 'srch_co',\n",
    "             'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_id',\n",
    "             'srch_destination_type_id', 'is_booking', 'cnt', 'hotel_continent',\n",
    "             'hotel_country', 'hotel_market', 'hotel_cluster']\n",
    "testcols = ['id', 'date_time', 'site_name', 'posa_continent', 'user_location_country',\n",
    "            'user_location_region', 'user_location_city', 'orig_destination_distance',\n",
    "            'user_id', 'is_mobile', 'is_package', 'channel', 'srch_ci', 'srch_co',\n",
    "            'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_id',\n",
    "            'srch_destination_type_id', 'hotel_continent', 'hotel_country', 'hotel_market']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding columns in testcols but not in traincols and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in testcols if col not in traincols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_booking', 'cnt', 'hotel_cluster']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in traincols if col not in testcols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know exactly what data colmuns I will be using eventually but I will define the data types for them here anyway just in case. Looking at the data most of the columns are actually non-negative integers so I can use unsigned integers for the most cases. Usage between uint8, uint32 and others was determined by the min and max values in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv( filename, cols, nrows=None ):\n",
    "    datecols = ['date_time', 'srch_ci', 'srch_co']\n",
    "    dateparser = lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    dtypes = {\n",
    "        'id': np.uint32,\n",
    "        'site_name': np.uint8,\n",
    "        'posa_continent': np.uint8,\n",
    "        'user_location_country': np.uint16,\n",
    "        'user_location_region': np.uint16,\n",
    "        'user_location_city': np.uint16,\n",
    "        'orig_destination_distance': np.float32,\n",
    "        'user_id': np.uint32,\n",
    "        'is_mobile': bool,\n",
    "        'is_package': bool,\n",
    "        'channel': np.uint8,\n",
    "        'srch_adults_cnt': np.uint8,\n",
    "        'srch_children_cnt': np.uint8,\n",
    "        'srch_rm_cnt': np.uint8,\n",
    "        'srch_destination_id': np.uint32,\n",
    "        'srch_destination_type_id': np.uint8,\n",
    "        'is_booking': bool,\n",
    "        'cnt': np.uint64,\n",
    "        'hotel_continent': np.uint8,\n",
    "        'hotel_country': np.uint16,\n",
    "        'hotel_market': np.uint16,\n",
    "        'hotel_cluster': np.uint8,\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filename,\n",
    "        nrows=nrows,\n",
    "        usecols=cols,\n",
    "        dtype=dtypes, # dtype can also specify datatypes for columns that do not excist in the particular datafile\n",
    "        parse_dates=[col for col in datecols if col in cols], # columns here must be also in usecols\n",
    "        date_parser=dateparser,\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37670293 entries, 0 to 37670292\n",
      "Data columns (total 24 columns):\n",
      "date_time                    datetime64[ns]\n",
      "site_name                    uint8\n",
      "posa_continent               uint8\n",
      "user_location_country        uint16\n",
      "user_location_region         uint16\n",
      "user_location_city           uint16\n",
      "orig_destination_distance    float32\n",
      "user_id                      uint32\n",
      "is_mobile                    bool\n",
      "is_package                   bool\n",
      "channel                      uint8\n",
      "srch_ci                      datetime64[ns]\n",
      "srch_co                      datetime64[ns]\n",
      "srch_adults_cnt              uint8\n",
      "srch_children_cnt            uint8\n",
      "srch_rm_cnt                  uint8\n",
      "srch_destination_id          uint32\n",
      "srch_destination_type_id     uint8\n",
      "is_booking                   bool\n",
      "cnt                          uint64\n",
      "hotel_continent              uint8\n",
      "hotel_country                uint16\n",
      "hotel_market                 uint16\n",
      "hotel_cluster                uint8\n",
      "dtypes: bool(3), datetime64[ns](3), float32(1), uint16(5), uint32(2), uint64(1), uint8(9)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "train = read_csv('data/train.csv.gz', nrows=None, cols=traincols)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these type definitions the entire training set of 37 million entries takes 2.3 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2528243 entries, 0 to 2528242\n",
      "Data columns (total 22 columns):\n",
      "id                           uint32\n",
      "date_time                    datetime64[ns]\n",
      "site_name                    uint8\n",
      "posa_continent               uint8\n",
      "user_location_country        uint16\n",
      "user_location_region         uint16\n",
      "user_location_city           uint16\n",
      "orig_destination_distance    float32\n",
      "user_id                      uint32\n",
      "is_mobile                    bool\n",
      "is_package                   bool\n",
      "channel                      uint8\n",
      "srch_ci                      datetime64[ns]\n",
      "srch_co                      datetime64[ns]\n",
      "srch_adults_cnt              uint8\n",
      "srch_children_cnt            uint8\n",
      "srch_rm_cnt                  uint8\n",
      "srch_destination_id          uint32\n",
      "srch_destination_type_id     uint8\n",
      "hotel_continent              uint8\n",
      "hotel_country                uint16\n",
      "hotel_market                 uint16\n",
      "dtypes: bool(2), datetime64[ns](3), float32(1), uint16(5), uint32(3), uint8(8)\n",
      "memory usage: 144.7 MB\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('data/test.csv.gz', cols=testcols)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding missing values in test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                0\n",
       "date_time                         0\n",
       "site_name                         0\n",
       "posa_continent                    0\n",
       "user_location_country             0\n",
       "user_location_region              0\n",
       "user_location_city                0\n",
       "orig_destination_distance    847461\n",
       "user_id                           0\n",
       "is_mobile                         0\n",
       "is_package                        0\n",
       "channel                           0\n",
       "srch_ci                          22\n",
       "srch_co                          17\n",
       "srch_adults_cnt                   0\n",
       "srch_children_cnt                 0\n",
       "srch_rm_cnt                       0\n",
       "srch_destination_id               0\n",
       "srch_destination_type_id          0\n",
       "hotel_continent                   0\n",
       "hotel_country                     0\n",
       "hotel_market                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some dates where the check in date is later than check out date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.srch_ci > test.srch_co).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Checking that all of the user_id-s in test set are contained in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids = set(test.user_id.unique())\n",
    "train_ids = set(train.user_id.unique())\n",
    "test_ids <= train_ids # issubset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, not all all user_ids that are in training data are in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17209"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids - test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract month and year field from the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['month'] = train['date_time'].dt.month.astype(np.uint8)\n",
    "train['year'] = train['date_time'].dt.year.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick 10000 users for smaller scale testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel_user_ids = sorted(random.sample(train_ids, 10000))\n",
    "sel_train = train[train.user_id.isin(sel_user_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = sel_train[((sel_train.year == 2013) | ((sel_train.year == 2014) & (sel_train.month < 8)))]\n",
    "t2 = sel_train[((sel_train.year == 2014) & (sel_train.month >= 8))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove click events from t2 as in original test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = t2[t2.is_booking == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0: Most common clusters\n",
    "Starting looking at the most common clusters and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_clusters = list(train.hotel_cluster.value_counts().head().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting `most_common_clusters` for every single row in selected test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [most_common_clusters for i in range(len(t2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Mean Average Precision with `mapk` from `ml_metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.066735918744228989"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [[l] for l in t2['hotel_cluster']]\n",
    "metrics.mapk(target, predictions, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.corr()['hotel_cluster']\n",
    "# Calculating the correlations takes a while. No linear correlations were anyhow found in tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating features from destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62106 entries, 0 to 62105\n",
      "Columns: 150 entries, srch_destination_id to d149\n",
      "dtypes: float64(149), int64(1)\n",
      "memory usage: 71.1 MB\n"
     ]
    }
   ],
   "source": [
    "dest = pd.read_csv('data/destinations.csv.gz')\n",
    "dest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>d140</th>\n",
       "      <th>d141</th>\n",
       "      <th>d142</th>\n",
       "      <th>d143</th>\n",
       "      <th>d144</th>\n",
       "      <th>d145</th>\n",
       "      <th>d146</th>\n",
       "      <th>d147</th>\n",
       "      <th>d148</th>\n",
       "      <th>d149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "      <td>-2.198657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.082564</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.165028</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "      <td>-2.181690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.183490</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.105819</td>\n",
       "      <td>-2.075407</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.118483</td>\n",
       "      <td>-2.140393</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.196379</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.192009</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.224164</td>\n",
       "      <td>-2.057548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.115485</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.161081</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "      <td>-2.177409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.189562</td>\n",
       "      <td>-2.187783</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.171153</td>\n",
       "      <td>-2.152303</td>\n",
       "      <td>-2.056618</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.145911</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.187356</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.191779</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.185161</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.194008</td>\n",
       "      <td>-2.188037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id        d1        d2        d3        d4        d5  \\\n",
       "0                    0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1                    1 -2.181690 -2.181690 -2.181690 -2.082564 -2.181690   \n",
       "2                    2 -2.183490 -2.224164 -2.224164 -2.189562 -2.105819   \n",
       "3                    3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4                    4 -2.189562 -2.187783 -2.194008 -2.171153 -2.152303   \n",
       "\n",
       "         d6        d7        d8        d9    ...         d140      d141  \\\n",
       "0 -1.897627 -2.198657 -2.198657 -1.897627    ...    -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.031597    ...    -2.165028 -2.181690   \n",
       "2 -2.075407 -2.224164 -2.118483 -2.140393    ...    -2.224164 -2.224164   \n",
       "3 -2.115485 -2.177409 -2.177409 -2.177409    ...    -2.161081 -2.177409   \n",
       "4 -2.056618 -2.194008 -2.194008 -2.145911    ...    -2.187356 -2.194008   \n",
       "\n",
       "       d142      d143      d144      d145      d146      d147      d148  \\\n",
       "0 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657 -2.198657   \n",
       "1 -2.165028 -2.181690 -2.181690 -2.165028 -2.181690 -2.181690 -2.181690   \n",
       "2 -2.196379 -2.224164 -2.192009 -2.224164 -2.224164 -2.224164 -2.224164   \n",
       "3 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409 -2.177409   \n",
       "4 -2.191779 -2.194008 -2.194008 -2.185161 -2.194008 -2.194008 -2.194008   \n",
       "\n",
       "       d149  \n",
       "0 -2.198657  \n",
       "1 -2.181690  \n",
       "2 -2.057548  \n",
       "3 -2.177409  \n",
       "4 -2.188037  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=3)\n",
    "dest_small = pca.fit_transform(dest[['d{}'.format(i) for i in range(1,150)]])\n",
    "dest_small = pd.DataFrame(dest_small)\n",
    "dest_small['srch_destination_id'] = dest['srch_destination_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>srch_destination_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044268</td>\n",
       "      <td>-0.169419</td>\n",
       "      <td>-0.032522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440761</td>\n",
       "      <td>-0.077405</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001033</td>\n",
       "      <td>-0.020677</td>\n",
       "      <td>-0.012108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480467</td>\n",
       "      <td>0.040345</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207253</td>\n",
       "      <td>0.042694</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  srch_destination_id\n",
       "0  0.044268 -0.169419 -0.032522                    0\n",
       "1  0.440761 -0.077405  0.091572                    1\n",
       "2 -0.001033 -0.020677 -0.012108                    2\n",
       "3  0.480467  0.040345  0.019320                    3\n",
       "4  0.207253  0.042694  0.011744                    4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance ratio that is retained using principal components analysis with 3 principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61572578062540773"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* New date features based on `date_time`, `srch_ci`, and `srch_co`.\n",
    "* Remove non-numeric columns like `date_time`.\n",
    "* Add in features from `dest_small`.\n",
    "* Replace any missing values with `-1`. (Initially planned to use unsigned integers for most of the variables, using `-1` as fill value would not work then. May test with replacing na's using the most common values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_fast_features(df):\n",
    "    # Assumes that the data frame date_time, srch_ci and srch_co are already converted to datetime.\n",
    "    props = {}\n",
    "    for prop in ['month', 'day', 'hour', 'minute', 'dayofweek', 'quarter']:\n",
    "        props[prop] = getattr(df['date_time'].dt, prop)\n",
    "\n",
    "    carryover = [p for p in df.columns if p not in ['date_time', 'srch_ci', 'srch_co']]\n",
    "    for prop in carryover:\n",
    "        props[prop] = df[prop]\n",
    "\n",
    "    date_props = ['month', 'day', 'dayofweek', 'quarter']\n",
    "    for prop in date_props:\n",
    "        props['ci_{}'.format(prop)] = getattr(df['srch_ci'].dt, prop)\n",
    "        props['co_{}'.format(prop)] = getattr(df['srch_co'].dt, prop)\n",
    "    props['stay_span'] = (df['srch_co'] - df['srch_ci']).astype('timedelta64[h]')\n",
    "\n",
    "    ret = pd.DataFrame(props)\n",
    "\n",
    "    ret = ret.join(dest_small, on='srch_destination_id', how='left', rsuffix='dest')\n",
    "    ret = ret.drop('srch_destination_iddest', axis=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = calc_fast_features(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mean values to fill missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forrest classifier\n",
    "Using 5-fold cross validation on the training data to estimate error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0652551 ,  0.06915912,  0.06577469,  0.06241378,  0.06689502])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [c for c in df.columns if c not in ['hotel_cluster']]\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=10, \n",
    "    min_weight_fraction_leaf=0.1,\n",
    ")\n",
    "scores = sklearn.cross_validation.cross_val_score(\n",
    "    clf,\n",
    "    df[predictors],\n",
    "    df['hotel_cluster'],\n",
    "    cv=5,\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier accuracy seems rather low here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forrest with binary classifier\n",
    "Random forests should work better if only a single hotel cluster is predicted at times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046900535362073816"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs = []\n",
    "unique_clusters = df['hotel_cluster'].unique()\n",
    "for cluster in unique_clusters:\n",
    "    df['target'] = 0\n",
    "    df.loc[df['hotel_cluster'] == cluster, 'target'] = 1\n",
    "    predictors = [c for c in df.columns if c not in ['hotel_cluster', 'target']]\n",
    "    probs = []\n",
    "    cv = sklearn.cross_validation.KFold(len(df), n_folds=5)\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(\n",
    "        n_estimators=10,\n",
    "        min_weight_fraction_leaf=0.1,\n",
    "    )\n",
    "    for i, (tr, te) in enumerate(cv):\n",
    "        clf.fit(df[predictors].iloc[tr], df['target'].iloc[tr])\n",
    "        preds = clf.predict_proba(df[predictors].iloc[te])\n",
    "        probs.append(p[1] for p in preds)\n",
    "    full_probs = itertools.chain.from_iterable(probs)\n",
    "    all_probs.append(list(full_probs))\n",
    "\n",
    "prediction_frame = pd.DataFrame(all_probs).T\n",
    "prediction_frame.columns = unique_clusters\n",
    "def find_top5(row):\n",
    "    return list(row.nlargest(5).index)\n",
    "\n",
    "preds = []\n",
    "for index, row in prediction_frame.iterrows():\n",
    "    preds.append(find_top5(row))\n",
    "\n",
    "metrics.mapk([[l] for l in t2['hotel_cluster']], preds, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just the most popular clusters gives better scores. The approach here isn't particularly promising.\n",
    "One thing to note is that the input is full of categorical features. Therefore, to properly apply machine learning converting those values to separate binary features may be more appropriate approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "Finding top hotel clusters for each destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_key(items):\n",
    "    return '_'.join([str(i) for i in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_cols = ['srch_destination_id']\n",
    "cluster_cols = match_cols + ['hotel_cluster']\n",
    "groups = t1.groupby(cluster_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_clusters = {}\n",
    "for name, group in groups:\n",
    "    clicks = len(group.is_booking[group.is_booking == False])\n",
    "    bookings = len(group.is_booking[group.is_booking == True])\n",
    "    \n",
    "    score = bookings + .15*clicks\n",
    "    \n",
    "    clus_name = make_key(name[:len(match_cols)])\n",
    "    if clus_name not in top_clusters:\n",
    "        top_clusters[clus_name] = {}\n",
    "    top_clusters[clus_name][name[-1]] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary has a key of `srch_destination_id` and each value is another dictionary, with hotel clusters as keys and scores as values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the top 5 for each destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_dict = {}\n",
    "for n in top_clusters:\n",
    "    tc = top_clusters[n]\n",
    "    top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]]\n",
    "    cluster_dict[n] = top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions based on destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24709650231774125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for index, row in t2.iterrows():\n",
    "    key = make_key([row[m] for m in match_cols])\n",
    "    if key in cluster_dict:\n",
    "        preds.append(cluster_dict[key])\n",
    "    else:\n",
    "        preds.append(most_common_clusters)\n",
    "\n",
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], preds, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data leak\n",
    "Utilizing the data leak, that allows matching users in the training set from the testing set using a set of columns inculid `user_location_country`, and `user_location_region`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_cols = [\n",
    "    'user_location_country',\n",
    "    'user_location_region',\n",
    "    'user_location_city',\n",
    "    'hotel_market',\n",
    "    'orig_destination_distance',\n",
    "]\n",
    "\n",
    "groups = t1.groupby(match_cols)\n",
    "\n",
    "def generate_exact_matches(row, match_cols):\n",
    "    index = tuple(row[t] for t in match_cols)\n",
    "    try:\n",
    "        group = groups.get_group(index)\n",
    "    except KeyError:\n",
    "        return []\n",
    "    clus = list(set(group.hotel_cluster))\n",
    "    return clus\n",
    "\n",
    "exact_matches = []\n",
    "for i in range(t2.shape[0]):\n",
    "    exact_matches.append(generate_exact_matches(t2.iloc[i], match_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining predictions\n",
    "Combine `exact_matches`, `preds`, and `most_common_clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f5(seq, idfun=None):\n",
    "    \"\"\"Uniquify a list by Peter Bengtsson\n",
    "    https://www.peterbe.com/plog/uniqifiers-benchmark\n",
    "    \"\"\"\n",
    "    if idfun is None:\n",
    "        def idfun(x):\n",
    "            return x\n",
    "\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen:\n",
    "            continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28300884955752215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_preds = [\n",
    "    f5(exact_matches[p] + preds[p] + most_common_clusters)[:5]\n",
    "    for p\n",
    "    in range(len(preds))\n",
    "]\n",
    "metrics.mapk([[l] for l in t2[\"hotel_cluster\"]], full_preds, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission file\n",
    "\n",
    "I'll clean up the code here and make a separate script that uses full dataset for generating a submission file.\n",
    "\n",
    "Here I'll just test the file making part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_p = [\" \".join([str(l) for l in p]) for p in full_preds]\n",
    "write_frame = [\"{},{}\".format(t2.index[i], write_p[i]) for i in range(len(full_preds))]\n",
    "write_frame = [\"id,hotel_clusters\"] + write_frame\n",
    "with open('predictions.csv', 'w+') as f:\n",
    "    f.write('\\n'.join(write_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "Peeter Piksarv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
